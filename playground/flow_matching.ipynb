{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1. 准备目标分布的数据\n",
    "# -----------------------\n",
    "\n",
    "# 目标分布 p1: 100 个点，均匀分布在 [100,1000]\n",
    "target_points = torch.linspace(100, 1000, steps=100)  # shape: [100]\n",
    "\n",
    "# 用于从这100个点里采样的函数\n",
    "def sample_from_p1(batch_size):\n",
    "    # 随机从 target_points 中抽取 batch_size 个点（有放回）\n",
    "    idx = torch.randint(0, len(target_points), size=(batch_size,))\n",
    "    return target_points[idx]\n",
    "\n",
    "# 初始分布 p0: 标准正态\n",
    "def sample_from_p0(batch_size):\n",
    "    return torch.randn(batch_size)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2. 定义网络 v_\\theta(t,x)\n",
    "# -----------------------\n",
    "class VelocityField(nn.Module):\n",
    "    \"\"\"\n",
    "    这里用一个非常简单的 MLP:\n",
    "    输入 (t, x)，输出一个标量速度 v。\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super(VelocityField, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        \"\"\"\n",
    "        t, x 均可视为 [batch_size] 的张量\n",
    "        将它们拼到一起变成 [batch_size, 2]\n",
    "        \"\"\"\n",
    "        # 拼接输入\n",
    "        inp = torch.stack([t, x], dim=1)  # shape: [batch_size, 2]\n",
    "        return self.net(inp).squeeze(-1)  # 输出 shape: [batch_size]\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3. 训练设置\n",
    "# -----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = VelocityField(hidden_dim=64).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# 超参数\n",
    "num_epochs = 2000\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 4. 训练循环\n",
    "# -----------------------\n",
    "for epoch in range(num_epochs):\n",
    "    # 1) 从 p0, p1 各采一批\n",
    "    x0 = sample_from_p0(batch_size).to(device)               # shape: [batch_size]\n",
    "    x1 = sample_from_p1(batch_size).to(device)               # shape: [batch_size]\n",
    "\n",
    "    # 2) 随机采一批 t \\in [0,1]\n",
    "    t = torch.rand(batch_size).to(device)                    # shape: [batch_size]\n",
    "\n",
    "    # 3) 计算线性插值 x_t = (1-t)*x0 + t*x1\n",
    "    x_t = (1.0 - t) * x0 + t * x1\n",
    "\n",
    "    # 4) 计算真速度(导数): (x_1 - x_0), 在该对 (x0,x1) 下是常数\n",
    "    true_velocity = x1 - x0  # shape: [batch_size]\n",
    "\n",
    "    # 5) 网络预测速度\n",
    "    pred_velocity = model(t, x_t)  # shape: [batch_size]\n",
    "\n",
    "    # 6) 计算并回传损失\n",
    "    loss = loss_fn(pred_velocity, true_velocity)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 200 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# 训练结束\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 5. 用训练好的模型来采样\n",
    "# -----------------------\n",
    "@torch.no_grad()\n",
    "def generate_samples_with_flow(num_samples=10, steps=50):\n",
    "    \"\"\"\n",
    "    使用简易的欧拉法从 t=0 积分到 t=1。\n",
    "    steps 越多，数值解越精细。\n",
    "    \"\"\"\n",
    "    # 1) 从 p0 采样初始点\n",
    "    x = sample_from_p0(num_samples).to(device)  # shape [num_samples]\n",
    "    t0, t1 = 0.0, 1.0\n",
    "    dt = (t1 - t0) / steps\n",
    "\n",
    "    for i in range(steps):\n",
    "        t_cur = t0 + i * dt\n",
    "        # 这里的 t_cur 是标量，但 x 是批量，所以要构造一个向量\n",
    "        t_vec = torch.full_like(x, t_cur)\n",
    "        # 计算速度\n",
    "        v_cur = model(t_vec, x)\n",
    "        # 欧拉步: x_{n+1} = x_n + dt * v(t_n, x_n)\n",
    "        x = x + dt * v_cur\n",
    "    \n",
    "    # 此时 x 就是 t=1 时得到的样本\n",
    "    return x.cpu().numpy()\n",
    "\n",
    "# -----------------------\n",
    "# 6. 测试采样\n",
    "# -----------------------\n",
    "generated = generate_samples_with_flow(num_samples=20, steps=100)\n",
    "print(\"生成的样本：\", generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
